# core.py
import os
import sys
import toml
from pathlib import Path
from datetime import datetime
import fnmatch
from typing import Dict, List
import textwrap
from . import utils, templates


class FileAggregator:
    def __init__(self, config_path: str = 'include.toml'):
        self.config = self._load_config(config_path)
        self.stats = {
            'processed_files': [],
            'total_size': 0,
            'file_types': {}
        }

    @staticmethod
    def generate_config(config_path):
        """ç”Ÿæˆå¸¦å®Œæ•´æ³¨é‡Šçš„é»˜è®¤é…ç½®æ–‡ä»¶"""
        config_content = textwrap.dedent("""\
            # ========================
            # æ–‡ä»¶èšåˆå·¥å…·é…ç½®æ–‡ä»¶
            # é»˜è®¤æ‰€æœ‰åŠŸèƒ½å…³é—­
            # ========================

            [include]
            # æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰
            # "src/**/*.js"  - åŒ¹é…srcç›®å½•æ‰€æœ‰jsæ–‡ä»¶
            # "docs/*.md"    - åŒ¹é…docsç›®å½•çš„mdæ–‡ä»¶
            patterns = ["*.py", "*.txt"]

            [exclude]
            # éœ€è¦æ’é™¤çš„æ–‡ä»¶æ¨¡å¼
            # "*.bak"       - æ‰€æœ‰å¤‡ä»½æ–‡ä»¶
            # "node_modules/" - æ’é™¤ç›®å½•
            patterns = ["test_*"]

            [output]
            filename = "result.txt"    # è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤ï¼šresult.txtï¼‰
            separator = "\\n\\n"    # æ–‡ä»¶åˆ†éš”ç¬¦ï¼ˆé»˜è®¤ç©ºä¸¤è¡Œï¼‰
            
            [features]
            # åŠŸèƒ½å¼€å…³é…ç½®
            enable_emojis = false    # å¯ç”¨è¡¨æƒ…ç¬¦å·ï¼ˆé»˜è®¤å…³é—­ï¼‰
            show_watermark = false    # æ˜¾ç¤ºæ°´å°ï¼ˆé»˜è®¤å…³é—­ï¼‰
            
            [filters]
            # è¿‡æ»¤æ¡ä»¶é…ç½®
            size_limit = 1024    # æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆå•ä½KBï¼Œ0=æ— é™åˆ¶ï¼‰

        """)

        try:
            config_path.write_text(config_content, encoding='utf-8')
            print(f"âœ… å·²ç”Ÿæˆå¸¦æ³¨é‡Šçš„é…ç½®æ–‡ä»¶ {config_path}")
            print("ğŸ‘‰ ä½¿ç”¨å»ºè®®ï¼š")
            print("1. ä¿®æ”¹ [include] åŒ…å«ä½ çš„ç›®æ ‡æ–‡ä»¶")
            print("2. å¼€å¯éœ€è¦çš„ [features] åŠŸèƒ½")
        except PermissionError:
            print(f"âŒ æ— å†™å…¥æƒé™: {config_path}")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆé…ç½®å¤±è´¥: {str(e)}")

    def _load_config(self, config_path: str) -> Dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = toml.load(f)
        except toml.TomlDecodeError:
            raise RuntimeError("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯")

        defaults = {
            'include': {'patterns': []},  # æ·»åŠ é»˜è®¤ç»“æ„
            'exclude': {'patterns': []},  # æ·»åŠ é»˜è®¤ç»“æ„
            'output': {
                'filename': 'print.txt',
                'separator': '\n\n'
            },
            'features': {
                'enable_emojis': True,
                'show_watermark': True,
            },
            'filters': {}
        }

        return utils.deep_update(defaults, config)

    def process_project(self, base_dir: str):
        """å¤„ç†æ•´ä¸ªé¡¹ç›®"""
        base_path = Path(base_dir)
        output_file = self.config['output']['filename']

        with open(output_file, 'w', encoding='utf-8') as out_f:
            if self.config['features']['show_watermark']:
                out_f.write(templates.get_watermark() + '\n\n')

            for pattern in self.config['include']['patterns']:
                for filepath in self._find_files(base_path, pattern):
                    self._process_file(filepath, base_path, out_f)

        print(f"\nå¤„ç†å®Œæˆ! {utils.format_stats(self.stats)}")

    def _find_files(self, base_path: Path, pattern: str) -> List[Path]:
        """æŸ¥æ‰¾åŒ¹é…æ–‡ä»¶"""
        if pattern.endswith('/'):
            dir_pattern = pattern.rstrip('/')
            dirs = [d for d in base_path.glob(dir_pattern) if d.is_dir()]
            return [f for d in dirs for f in d.rglob('*') if f.is_file()]
        return [f for f in base_path.rglob(pattern) if f.is_file()]

    def _process_file(self, filepath: Path, base_path: Path, out_f):
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        if not self._should_include(filepath):
            return

        try:
            content = filepath.read_text(encoding='utf-8')
            rel_path = filepath.relative_to(base_path)

            self._update_stats(filepath, content)

            header = self._get_file_header(filepath, rel_path, content)
            processed_content = self._preprocess_content(content)
            footer = self._get_file_footer()

            out_f.write(f"{header}{processed_content}{footer}")
            print(f"âœ… å·²å¤„ç†: {rel_path} {utils.get_file_emoji(filepath)}")

        except UnicodeDecodeError:
            print(f"âš ï¸ è·³è¿‡äºŒè¿›åˆ¶æ–‡ä»¶: {filepath.name}")
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {filepath.name} - {str(e)}")

    def _should_include(self, filepath: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡ä»¶"""
        for pattern in self.config['exclude']:
            if fnmatch.fnmatch(str(filepath), pattern):
                return False

        if 'size_limit' in self.config['filters']:
            file_size = filepath.stat().st_size
            if file_size > self.config['filters']['size_limit'] * 1024:
                return False

        return True

    def _update_stats(self, filepath: Path, content: str):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        file_stat = {
            'path': filepath,
            'size': filepath.stat().st_size,
            'modified': datetime.fromtimestamp(filepath.stat().st_mtime)
        }
        self.stats['processed_files'].append(file_stat)
        self.stats['total_size'] += file_stat['size']
        ext = filepath.suffix.lower()
        self.stats['file_types'][ext] = self.stats['file_types'].get(ext, 0) + 1

    def _get_file_header(self, filepath: Path, rel_path: str, content: str) -> str:
        """ç”Ÿæˆæ–‡ä»¶å¤´éƒ¨"""
        header = []
        if self.config['features']['enable_emojis']:
            header.append(f"{utils.get_file_emoji(filepath)} {rel_path}")
        else:
            header.append(str(rel_path))

        header.append(f"ğŸ“… ä¿®æ”¹æ—¶é—´: {datetime.fromtimestamp(filepath.stat().st_mtime):%Y-%m-%d %H:%M}")
        header.append(f"ğŸ“ æ–‡ä»¶å¤§å°: {utils.format_size(filepath.stat().st_size)}")

        return '\n'.join(header) + '\n\n'

    def _preprocess_content(self, content: str) -> str:
        """å†…å®¹é¢„å¤„ç†"""
        if self.config['filters'].get('trim_trailing_whitespace', False):
            content = '\n'.join(line.rstrip() for line in content.split('\n'))
        if self.config['filters'].get('remove_empty_lines', False):
            content = '\n'.join(line for line in content.split('\n') if line.strip())
        return content

    def _get_file_footer(self) -> str:
        """ç”Ÿæˆæ–‡ä»¶å°¾éƒ¨"""
        if self.config['output']['format'] == 'markdown':
            return "\n```"+self.config['output']['separator']
        return self.config['output']['separator']